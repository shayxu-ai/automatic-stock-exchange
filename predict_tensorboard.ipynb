{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd087e4668eb327ab3c4ab758a072c7ead37fffe33bf1bf61467c1b402e157a0e55",
   "display_name": "Python 3.7.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\yxu94\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\yxu94\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\yxu94\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs/hparam_tuning'\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2    1160\n1     874\n0     297\nName: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 一些超参\n",
    "to_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")      # 今日日期       \n",
    "re_download = True              # 重新下载数据\n",
    "re_train = True                 # 重新训练\n",
    "predict_period = 15             # 预测天数\n",
    "history_period = 400            # 分析天数\n",
    "epoch = 200\n",
    "start_date = '2010-01-01'       # 最早数据\n",
    "threshold_flat = 0.007           # 股价持平的阈值\n",
    "stock_code_list = pd.read_csv('stock_codes.csv')['code']    # 获取需要预测的股票代码\n",
    "\n",
    "# 一些设置\n",
    "verify_period = 2              # 验证周期\n",
    "\n",
    "i = 0\n",
    "stock_code = 'sz.000858'\n",
    "stock_info_path = \"stock_info/\" + stock_code + \".csv\"       # 文件路径\n",
    "# 读取csv文件\n",
    "stock = pd.read_csv(stock_info_path, parse_dates=['date'])\n",
    "\n",
    "if i == 0:\n",
    "    pass\n",
    "else:\n",
    "    stock = stock[:-i]\n",
    "\n",
    "# 准备数据\n",
    "stock['close_nomalized'] = (stock['close']-stock['close'].min())/(stock['close'].max()-stock['close'].min())        # 收盘价 归一化\n",
    "stock['future_price'] = stock['close'].rolling(predict_period).mean().shift(-predict_period)                        # 未来股价均值(不包含当日收盘价)\n",
    "\n",
    "def flat_or_not(x):\n",
    "    if x >= threshold_flat:\n",
    "        return 2       # 涨\n",
    "    elif x <= -threshold_flat:\n",
    "        return 1       # 跌\n",
    "    else:\n",
    "        return 0       # 持平\n",
    "\n",
    "stock['label'] = ((stock['future_price'] - stock['close']) / stock['close']).apply(flat_or_not)\n",
    "\n",
    "n = len(stock)\n",
    "x = np.array([stock[['close_nomalized', 'turn']][i:i+history_period] for i in range(n-history_period-predict_period+1)]).reshape(-1, 20, 20, 2) # 输入 400天\n",
    "x = x[:, :, :, :, np.newaxis]\n",
    "y = stock['label'][history_period-1:].values[:-predict_period]                                               # 标签 \n",
    "\n",
    "print(pd.DataFrame(y)[0].value_counts())    # 打印三种类别样本的个数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2331, 400, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "np.array([stock[['close_nomalized', 'turn']][i:i+history_period] for i in range(n-history_period-predict_period+1)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[[[0.05146546],\n",
       "          [0.695795  ]],\n",
       "\n",
       "         [[0.05246567],\n",
       "          [0.766646  ]],\n",
       "\n",
       "         [[0.04991968],\n",
       "          [1.128226  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04270603],\n",
       "          [0.747497  ]],\n",
       "\n",
       "         [[0.04346377],\n",
       "          [0.614937  ]],\n",
       "\n",
       "         [[0.04461552],\n",
       "          [0.478751  ]]],\n",
       "\n",
       "\n",
       "        [[[0.04631285],\n",
       "          [0.763156  ]],\n",
       "\n",
       "         [[0.0438881 ],\n",
       "          [0.552596  ]],\n",
       "\n",
       "         [[0.04428212],\n",
       "          [0.601669  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04225139],\n",
       "          [0.499899  ]],\n",
       "\n",
       "         [[0.04161489],\n",
       "          [0.745284  ]],\n",
       "\n",
       "         [[0.04188767],\n",
       "          [0.381774  ]]],\n",
       "\n",
       "\n",
       "        [[[0.04161489],\n",
       "          [0.310684  ]],\n",
       "\n",
       "         [[0.04112994],\n",
       "          [0.52691   ]],\n",
       "\n",
       "         [[0.03952354],\n",
       "          [0.638421  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04152396],\n",
       "          [0.506467  ]],\n",
       "\n",
       "         [[0.04255448],\n",
       "          [0.505175  ]],\n",
       "\n",
       "         [[0.04191798],\n",
       "          [0.482984  ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.05883066],\n",
       "          [0.720553  ]],\n",
       "\n",
       "         [[0.0586488 ],\n",
       "          [0.639869  ]],\n",
       "\n",
       "         [[0.06077047],\n",
       "          [0.776119  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.06507441],\n",
       "          [0.50564   ]],\n",
       "\n",
       "         [[0.0650441 ],\n",
       "          [0.470604  ]],\n",
       "\n",
       "         [[0.06364987],\n",
       "          [0.347971  ]]],\n",
       "\n",
       "\n",
       "        [[[0.0644076 ],\n",
       "          [0.348271  ]],\n",
       "\n",
       "         [[0.06425605],\n",
       "          [0.29384   ]],\n",
       "\n",
       "         [[0.06586246],\n",
       "          [0.598519  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07146971],\n",
       "          [0.920295  ]],\n",
       "\n",
       "         [[0.07065135],\n",
       "          [0.688252  ]],\n",
       "\n",
       "         [[0.07253054],\n",
       "          [0.572769  ]]],\n",
       "\n",
       "\n",
       "        [[[0.07289425],\n",
       "          [0.410264  ]],\n",
       "\n",
       "         [[0.07131816],\n",
       "          [0.280927  ]],\n",
       "\n",
       "         [[0.06910557],\n",
       "          [0.515432  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07140909],\n",
       "          [0.847145  ]],\n",
       "\n",
       "         [[0.07183342],\n",
       "          [0.451813  ]],\n",
       "\n",
       "         [[0.07298518],\n",
       "          [0.385367  ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.05246567],\n",
       "          [0.766646  ]],\n",
       "\n",
       "         [[0.04991968],\n",
       "          [1.128226  ]],\n",
       "\n",
       "         [[0.04707059],\n",
       "          [1.625736  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04346377],\n",
       "          [0.614937  ]],\n",
       "\n",
       "         [[0.04461552],\n",
       "          [0.478751  ]],\n",
       "\n",
       "         [[0.04631285],\n",
       "          [0.763156  ]]],\n",
       "\n",
       "\n",
       "        [[[0.0438881 ],\n",
       "          [0.552596  ]],\n",
       "\n",
       "         [[0.04428212],\n",
       "          [0.601669  ]],\n",
       "\n",
       "         [[0.04497924],\n",
       "          [0.43405   ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04161489],\n",
       "          [0.745284  ]],\n",
       "\n",
       "         [[0.04188767],\n",
       "          [0.381774  ]],\n",
       "\n",
       "         [[0.04161489],\n",
       "          [0.310684  ]]],\n",
       "\n",
       "\n",
       "        [[[0.04112994],\n",
       "          [0.52691   ]],\n",
       "\n",
       "         [[0.03952354],\n",
       "          [0.638421  ]],\n",
       "\n",
       "         [[0.03958415],\n",
       "          [0.318627  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04255448],\n",
       "          [0.505175  ]],\n",
       "\n",
       "         [[0.04191798],\n",
       "          [0.482984  ]],\n",
       "\n",
       "         [[0.04112994],\n",
       "          [0.675982  ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0586488 ],\n",
       "          [0.639869  ]],\n",
       "\n",
       "         [[0.06077047],\n",
       "          [0.776119  ]],\n",
       "\n",
       "         [[0.06092201],\n",
       "          [0.632056  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0650441 ],\n",
       "          [0.470604  ]],\n",
       "\n",
       "         [[0.06364987],\n",
       "          [0.347971  ]],\n",
       "\n",
       "         [[0.0644076 ],\n",
       "          [0.348271  ]]],\n",
       "\n",
       "\n",
       "        [[[0.06425605],\n",
       "          [0.29384   ]],\n",
       "\n",
       "         [[0.06586246],\n",
       "          [0.598519  ]],\n",
       "\n",
       "         [[0.06546843],\n",
       "          [0.313669  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07065135],\n",
       "          [0.688252  ]],\n",
       "\n",
       "         [[0.07253054],\n",
       "          [0.572769  ]],\n",
       "\n",
       "         [[0.07289425],\n",
       "          [0.410264  ]]],\n",
       "\n",
       "\n",
       "        [[[0.07131816],\n",
       "          [0.280927  ]],\n",
       "\n",
       "         [[0.06910557],\n",
       "          [0.515432  ]],\n",
       "\n",
       "         [[0.06937835],\n",
       "          [0.590865  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07183342],\n",
       "          [0.451813  ]],\n",
       "\n",
       "         [[0.07298518],\n",
       "          [0.385367  ]],\n",
       "\n",
       "         [[0.07480375],\n",
       "          [0.466199  ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.04991968],\n",
       "          [1.128226  ]],\n",
       "\n",
       "         [[0.04707059],\n",
       "          [1.625736  ]],\n",
       "\n",
       "         [[0.04688873],\n",
       "          [0.961059  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04461552],\n",
       "          [0.478751  ]],\n",
       "\n",
       "         [[0.04631285],\n",
       "          [0.763156  ]],\n",
       "\n",
       "         [[0.0438881 ],\n",
       "          [0.552596  ]]],\n",
       "\n",
       "\n",
       "        [[[0.04428212],\n",
       "          [0.601669  ]],\n",
       "\n",
       "         [[0.04497924],\n",
       "          [0.43405   ]],\n",
       "\n",
       "         [[0.04361531],\n",
       "          [0.404599  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04188767],\n",
       "          [0.381774  ]],\n",
       "\n",
       "         [[0.04161489],\n",
       "          [0.310684  ]],\n",
       "\n",
       "         [[0.04112994],\n",
       "          [0.52691   ]]],\n",
       "\n",
       "\n",
       "        [[[0.03952354],\n",
       "          [0.638421  ]],\n",
       "\n",
       "         [[0.03958415],\n",
       "          [0.318627  ]],\n",
       "\n",
       "         [[0.03864456],\n",
       "          [0.358979  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.04191798],\n",
       "          [0.482984  ]],\n",
       "\n",
       "         [[0.04112994],\n",
       "          [0.675982  ]],\n",
       "\n",
       "         [[0.04209984],\n",
       "          [0.420773  ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.06077047],\n",
       "          [0.776119  ]],\n",
       "\n",
       "         [[0.06092201],\n",
       "          [0.632056  ]],\n",
       "\n",
       "         [[0.06040675],\n",
       "          [0.371976  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.06364987],\n",
       "          [0.347971  ]],\n",
       "\n",
       "         [[0.0644076 ],\n",
       "          [0.348271  ]],\n",
       "\n",
       "         [[0.06425605],\n",
       "          [0.29384   ]]],\n",
       "\n",
       "\n",
       "        [[[0.06586246],\n",
       "          [0.598519  ]],\n",
       "\n",
       "         [[0.06546843],\n",
       "          [0.313669  ]],\n",
       "\n",
       "         [[0.06680205],\n",
       "          [0.493779  ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07253054],\n",
       "          [0.572769  ]],\n",
       "\n",
       "         [[0.07289425],\n",
       "          [0.410264  ]],\n",
       "\n",
       "         [[0.07131816],\n",
       "          [0.280927  ]]],\n",
       "\n",
       "\n",
       "        [[[0.06910557],\n",
       "          [0.515432  ]],\n",
       "\n",
       "         [[0.06937835],\n",
       "          [0.590865  ]],\n",
       "\n",
       "         [[0.07077259],\n",
       "          [0.44386   ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.07298518],\n",
       "          [0.385367  ]],\n",
       "\n",
       "         [[0.07480375],\n",
       "          [0.466199  ]],\n",
       "\n",
       "         [[0.07559179],\n",
       "          [0.43425   ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.31691571],\n",
       "          [0.6869    ]],\n",
       "\n",
       "         [[0.31415755],\n",
       "          [0.7113    ]],\n",
       "\n",
       "         [[0.31061134],\n",
       "          [0.7112    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.34234535],\n",
       "          [0.7461    ]],\n",
       "\n",
       "         [[0.35737884],\n",
       "          [1.0002    ]],\n",
       "\n",
       "         [[0.36204649],\n",
       "          [0.9056    ]]],\n",
       "\n",
       "\n",
       "        [[[0.37138181],\n",
       "          [0.8333    ]],\n",
       "\n",
       "         [[0.38502107],\n",
       "          [1.1613    ]],\n",
       "\n",
       "         [[0.38620313],\n",
       "          [0.8691    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.36989664],\n",
       "          [0.7079    ]],\n",
       "\n",
       "         [[0.36998757],\n",
       "          [0.4996    ]],\n",
       "\n",
       "         [[0.36259206],\n",
       "          [0.578     ]]],\n",
       "\n",
       "\n",
       "        [[[0.36168278],\n",
       "          [0.4392    ]],\n",
       "\n",
       "         [[0.349559  ],\n",
       "          [0.6993    ]],\n",
       "\n",
       "         [[0.3585306 ],\n",
       "          [0.5978    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.35471161],\n",
       "          [0.5656    ]],\n",
       "\n",
       "         [[0.35304459],\n",
       "          [0.3499    ]],\n",
       "\n",
       "         [[0.35646955],\n",
       "          [0.878     ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.79062225],\n",
       "          [0.4114    ]],\n",
       "\n",
       "         [[0.79244082],\n",
       "          [0.2927    ]],\n",
       "\n",
       "         [[0.82284121],\n",
       "          [0.5106    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.8093535 ],\n",
       "          [0.7742    ]],\n",
       "\n",
       "         [[0.81950717],\n",
       "          [0.6956    ]],\n",
       "\n",
       "         [[0.85618161],\n",
       "          [0.7746    ]]],\n",
       "\n",
       "\n",
       "        [[[0.8519686 ],\n",
       "          [0.6572    ]],\n",
       "\n",
       "         [[0.91298154],\n",
       "          [1.0878    ]],\n",
       "\n",
       "         [[0.88294487],\n",
       "          [0.6361    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.91089019],\n",
       "          [0.7341    ]],\n",
       "\n",
       "         [[0.84445185],\n",
       "          [1.0992    ]],\n",
       "\n",
       "         [[0.8317825 ],\n",
       "          [0.6561    ]]],\n",
       "\n",
       "\n",
       "        [[[0.80480708],\n",
       "          [0.7613    ]],\n",
       "\n",
       "         [[0.83214621],\n",
       "          [0.672     ]],\n",
       "\n",
       "         [[0.80692874],\n",
       "          [0.6431    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.75100779],\n",
       "          [0.3345    ]],\n",
       "\n",
       "         [[0.74661292],\n",
       "          [0.4727    ]],\n",
       "\n",
       "         [[0.73200376],\n",
       "          [0.4907    ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.31415755],\n",
       "          [0.7113    ]],\n",
       "\n",
       "         [[0.31061134],\n",
       "          [0.7112    ]],\n",
       "\n",
       "         [[0.32373534],\n",
       "          [1.4045    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.35737884],\n",
       "          [1.0002    ]],\n",
       "\n",
       "         [[0.36204649],\n",
       "          [0.9056    ]],\n",
       "\n",
       "         [[0.37138181],\n",
       "          [0.8333    ]]],\n",
       "\n",
       "\n",
       "        [[[0.38502107],\n",
       "          [1.1613    ]],\n",
       "\n",
       "         [[0.38620313],\n",
       "          [0.8691    ]],\n",
       "\n",
       "         [[0.38502107],\n",
       "          [0.7238    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.36998757],\n",
       "          [0.4996    ]],\n",
       "\n",
       "         [[0.36259206],\n",
       "          [0.578     ]],\n",
       "\n",
       "         [[0.36168278],\n",
       "          [0.4392    ]]],\n",
       "\n",
       "\n",
       "        [[[0.349559  ],\n",
       "          [0.6993    ]],\n",
       "\n",
       "         [[0.3585306 ],\n",
       "          [0.5978    ]],\n",
       "\n",
       "         [[0.3556512 ],\n",
       "          [0.4448    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.35304459],\n",
       "          [0.3499    ]],\n",
       "\n",
       "         [[0.35646955],\n",
       "          [0.878     ]],\n",
       "\n",
       "         [[0.36137969],\n",
       "          [0.5895    ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.79244082],\n",
       "          [0.2927    ]],\n",
       "\n",
       "         [[0.82284121],\n",
       "          [0.5106    ]],\n",
       "\n",
       "         [[0.80783803],\n",
       "          [0.3862    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.81950717],\n",
       "          [0.6956    ]],\n",
       "\n",
       "         [[0.85618161],\n",
       "          [0.7746    ]],\n",
       "\n",
       "         [[0.8519686 ],\n",
       "          [0.6572    ]]],\n",
       "\n",
       "\n",
       "        [[[0.91298154],\n",
       "          [1.0878    ]],\n",
       "\n",
       "         [[0.88294487],\n",
       "          [0.6361    ]],\n",
       "\n",
       "         [[0.84293638],\n",
       "          [0.8113    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.84445185],\n",
       "          [1.0992    ]],\n",
       "\n",
       "         [[0.8317825 ],\n",
       "          [0.6561    ]],\n",
       "\n",
       "         [[0.80480708],\n",
       "          [0.7613    ]]],\n",
       "\n",
       "\n",
       "        [[[0.83214621],\n",
       "          [0.672     ]],\n",
       "\n",
       "         [[0.80692874],\n",
       "          [0.6431    ]],\n",
       "\n",
       "         [[0.82087109],\n",
       "          [0.5578    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.74661292],\n",
       "          [0.4727    ]],\n",
       "\n",
       "         [[0.73200376],\n",
       "          [0.4907    ]],\n",
       "\n",
       "         [[0.76222229],\n",
       "          [0.6065    ]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.31061134],\n",
       "          [0.7112    ]],\n",
       "\n",
       "         [[0.32373534],\n",
       "          [1.4045    ]],\n",
       "\n",
       "         [[0.31646107],\n",
       "          [0.6767    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.36204649],\n",
       "          [0.9056    ]],\n",
       "\n",
       "         [[0.37138181],\n",
       "          [0.8333    ]],\n",
       "\n",
       "         [[0.38502107],\n",
       "          [1.1613    ]]],\n",
       "\n",
       "\n",
       "        [[[0.38620313],\n",
       "          [0.8691    ]],\n",
       "\n",
       "         [[0.38502107],\n",
       "          [0.7238    ]],\n",
       "\n",
       "         [[0.37535235],\n",
       "          [1.0026    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.36259206],\n",
       "          [0.578     ]],\n",
       "\n",
       "         [[0.36168278],\n",
       "          [0.4392    ]],\n",
       "\n",
       "         [[0.349559  ],\n",
       "          [0.6993    ]]],\n",
       "\n",
       "\n",
       "        [[[0.3585306 ],\n",
       "          [0.5978    ]],\n",
       "\n",
       "         [[0.3556512 ],\n",
       "          [0.4448    ]],\n",
       "\n",
       "         [[0.35316582],\n",
       "          [0.7731    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.35646955],\n",
       "          [0.878     ]],\n",
       "\n",
       "         [[0.36137969],\n",
       "          [0.5895    ]],\n",
       "\n",
       "         [[0.36225866],\n",
       "          [0.5808    ]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.82284121],\n",
       "          [0.5106    ]],\n",
       "\n",
       "         [[0.80783803],\n",
       "          [0.3862    ]],\n",
       "\n",
       "         [[0.82565999],\n",
       "          [0.4448    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.85618161],\n",
       "          [0.7746    ]],\n",
       "\n",
       "         [[0.8519686 ],\n",
       "          [0.6572    ]],\n",
       "\n",
       "         [[0.91298154],\n",
       "          [1.0878    ]]],\n",
       "\n",
       "\n",
       "        [[[0.88294487],\n",
       "          [0.6361    ]],\n",
       "\n",
       "         [[0.84293638],\n",
       "          [0.8113    ]],\n",
       "\n",
       "         [[0.82299276],\n",
       "          [0.7273    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.8317825 ],\n",
       "          [0.6561    ]],\n",
       "\n",
       "         [[0.80480708],\n",
       "          [0.7613    ]],\n",
       "\n",
       "         [[0.83214621],\n",
       "          [0.672     ]]],\n",
       "\n",
       "\n",
       "        [[[0.80692874],\n",
       "          [0.6431    ]],\n",
       "\n",
       "         [[0.82087109],\n",
       "          [0.5578    ]],\n",
       "\n",
       "         [[0.76331343],\n",
       "          [0.8677    ]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.73200376],\n",
       "          [0.4907    ]],\n",
       "\n",
       "         [[0.76222229],\n",
       "          [0.6065    ]],\n",
       "\n",
       "         [[0.7808323 ],\n",
       "          [0.7429    ]]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, 3, activation='relu', input_shape=(20, 20, 1)))         # 卷积核的个数 => 输出的维度\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3))\n",
    "    model.compile(optimizer='adam', \n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "            \n",
    "    model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test), initial_epoch=10, callbacks = [tf.keras.callbacks.TensorBoard(logdir), hp.KerasCallback(logdir, hparams)])\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  }
 ]
}