{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd087e4668eb327ab3c4ab758a072c7ead37fffe33bf1bf61467c1b402e157a0e55",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 通过CNN分析价格曲线，预测涨跌  \n",
    " \n",
    "......\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib. pyplot as plt \n",
    "\n",
    "import baostock as bs   # 股票宝，获取股票数据\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Reshape,Dropout,Activation\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    # 从股票宝下载股票数据\n",
    "    bs.login()\n",
    "    for stock_code in tqdm(stock_code_list):\n",
    "        stock_info_path = \"stock_info/\" + stock_code + \".csv\"\n",
    "        if not os.path.exists(stock_info_path) or re_download:\n",
    "            rs = bs.query_history_k_data(stock_code, \"date, open, close, volume, amount, turn, pctChg\", start_date=start_date, end_date=to_date, frequency=\"d\", adjustflag=\"3\")\n",
    "            # volume 成交量\n",
    "            # amount 成交额\n",
    "            # turn 换手率\n",
    "\n",
    "            data_list = []\n",
    "            while (rs.error_code == '0') & rs.next():  # 获取一条记录，将记录合并在一起\n",
    "                data_list.append(rs.get_row_data())\n",
    "            result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "            result.to_csv(stock_info_path, index=False)\n",
    "    bs.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    stock_info_path = \"stock_info/\" + stock_code + \".csv\"       # 文件路径\n",
    "    # 读取csv文件\n",
    "    stock = pd.read_csv(stock_info_path, parse_dates=['date'])\n",
    "    \n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        stock = stock[:-i]\n",
    "\n",
    "    # 准备数据\n",
    "    stock['close_nomalized'] = (stock['close']-stock['close'].min())/(stock['close'].max()-stock['close'].min())        # 收盘价 归一化\n",
    "    stock['volume_nomalized'] = (stock['volume']-stock['volume'].min())/(stock['volume'].max()-stock['volume'].min())   # 交易量 归一化\n",
    "    stock['avg_price'] = stock['close'].rolling(predict_period).mean()                                                  # 最近周期内的平均股价\n",
    "    stock = stock[predict_period-1:]\n",
    "    stock['future_price'] = stock['close'].rolling(predict_period).mean().shift(-predict_period)                        # 未来股价均值(不包含当日收盘价)\n",
    "    # stock = stock.dropna(axis=0)                                                                                      # 去除空值\n",
    "\n",
    "    def flat_or_not(x):\n",
    "        if x >= threshold_flat:\n",
    "            return 2       # 涨\n",
    "        elif x <= -threshold_flat:\n",
    "            return 1       # 跌\n",
    "        elif np.isnan(x):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return 0       # 持平\n",
    "\n",
    "    stock['label'] = ((stock['future_price'] - stock['avg_price']) / stock['avg_price']).apply(flat_or_not)\n",
    "\n",
    "    n = len(stock)\n",
    "\n",
    "    if not cnn_3d_flag:\n",
    "        x = np.array([stock['close_nomalized'][i:i+history_period] for i in range(n-history_period-predict_period+1)]).reshape(-1, 20, 20) # 输入 400天 （0:400）~（n-400-predict~n）\n",
    "        x = x[:, :, :, np.newaxis]\n",
    "    else:\n",
    "        x = np.array([stock[['close_nomalized', 'volume_nomalized']][i:i+history_period] for i in range(n-history_period+1)]).reshape(-1, 20, 20, 2) # 输入 400天 + 交易量\n",
    "        x = x[:, :, :, :, np.newaxis]\n",
    "\n",
    "        x, x_valid = np.split(x, [-predict_period])\n",
    "\n",
    "    y = stock['label'][history_period-1:].values[:-predict_period]                                               # 标签 \n",
    "    # print(pd.DataFrame(y)[0].value_counts())    # 打印三种类别样本的个数。\n",
    "    return stock, x, y, x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv2D(32, 3, activation='relu', input_shape=(20, 20, 1)))         # 卷积核的个数 => 输出的维度\n",
    "        model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dense(3))\n",
    "        model.compile(optimizer='adam', \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "        # model = tf.keras.models.load_model('saved_model.h5')\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=6, verbose=1, mode='auto')\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test), callbacks = [monitor])\n",
    "        # tf.saved_model.save(model, 'saved_model/')\n",
    "        model.save('saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_3d():\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv3D(32, (3, 3, 1), activation='relu', input_shape=(20, 20, 2, 1)))         # 卷积核的个数 => 输出的维度\n",
    "        model.add(keras.layers.MaxPool3D((2, 2, 1)))\n",
    "        model.add(keras.layers.Conv3D(64, (3, 3, 1), activation='relu'))\n",
    "        model.add(keras.layers.MaxPool3D((2, 2, 1)))\n",
    "        model.add(keras.layers.Conv3D(64, (3, 3, 1), activation='relu'))\n",
    "\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dense(3))\n",
    "        model.compile(optimizer='adam', \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "        # model = tf.keras.models.load_model('saved_model.h5')\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=6, verbose=1, mode='auto')\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test), callbacks = [monitor])\n",
    "        # tf.saved_model.save(model, 'saved_model/')\n",
    "        model.save('saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    \"\"\"\n",
    "        preprocess中已经根据i，缩短了stock从而x,y都无需额外处理\n",
    "    \"\"\"\n",
    "    # 读取模型\n",
    "    model = tf.keras.models.load_model('saved_model.h5')\n",
    "    # model = tf.saved_model.load('saved_model/')\n",
    "    xi = tf.convert_to_tensor(x[[-1]], tf.float32, name='inputs')\n",
    "    predictions = model(xi)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    class_names = {\n",
    "        0: \"持平\",\n",
    "        1: \"跌\",\n",
    "        2: \"涨\"\n",
    "    }\n",
    "    # print(\"Price: {}\".format(stock['close'].values[-1]))\n",
    "    # print(\n",
    "    #     \"Stock {} most likely {} with a {:.2f} percent confidence.\"\n",
    "    #     .format(stock_code, class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    # )\n",
    "    return stock['close'].values[-1], np.argmax(score), 100 * np.max(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_v2():\n",
    "    \"\"\"\n",
    "        不重新训练模型，一次性预测所有天数\n",
    "    \"\"\"\n",
    "\n",
    "    # 读取模型\n",
    "    model = tf.keras.models.load_model('saved_model.h5')\n",
    "    score = tf.nn.softmax(model(x_valid))\n",
    "    a = pd.Series([np.argmax(item) for item in score])\n",
    "    n = len(stock)\n",
    "    a.index=stock.index[-predict_period:]\n",
    "    stock['label_valid'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")      # 今日日期\n",
    "re_download = False              # 重新下载数据\n",
    "\n",
    "# 超参\n",
    "re_train = False                 # 重新训练\n",
    "history_period = 400             # 分析天数\n",
    "predict_period = 6               # 预测天数\n",
    "epoch = 200                      # 训练最大圈数\n",
    "start_date = '2010-01-01'        # 最早数据\n",
    "threshold_flat = 0.007           # 判定股价持平的阈值\n",
    "threshold_prob = 70              # 买卖时概率的阈值\n",
    "stock_code_list = pd.read_csv('stock_codes.csv')['code']    # 需要预测的股票代码\n",
    "cnn_3d_flag = True               # 3维CNN\n",
    "\n",
    "# 验证设置\n",
    "verify_period = 20                # 验证周期\n",
    "simulation = {\n",
    "    'bought': False,\n",
    "    'price': 0,\n",
    "    'asset': 1\n",
    "}\n",
    "\n",
    "# 下载数据\n",
    "download()\n",
    "\n",
    "df_verification = pd.Series(dtype=np.float64)\n",
    "for i in tqdm(range(verify_period, -1, -1)):              # 验证天数， n ~ 0\n",
    "    for stock_code in (stock_code_list):        # 股票代码\n",
    "        stock, x, y, x_valid = preprocess()                  # 预处理\n",
    "    \n",
    "        try:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2,shuffle=True)        # 分割数据集\n",
    "            if re_train:\n",
    "                if not cnn_3d_flag:\n",
    "                    train()\n",
    "                else:\n",
    "                    train_3d()\n",
    "            predict()                # 预测\n",
    "        except Exception as e:\n",
    "            with open(\"logs/log.csv\", 'a') as f:\n",
    "                csv.writer(f).writerow([stock_code, e, e.__traceback__.tb_lineno])\n",
    "\n",
    "# df_verification = df_verification.reindex(index=stock.index[-verify_period-1:])\n",
    "df_verification.index = stock.index[-verify_period-1:]\n",
    "stock['label_predict'] = df_verification\n",
    "stock.to_csv('prediction_results/'+stock_code+'.csv')\n",
    "print(stock_code, simulation['asset'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock, x, y, x_valid = preprocess()\n",
    "predict_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date       open      close       volume        amount      turn  \\\n",
       "2735 2021-04-07  5141.6556  5103.7428  14576374800  2.462712e+11  0.525246   \n",
       "2736 2021-04-08  5078.2627  5112.2086  14177104700  2.284220e+11  0.510867   \n",
       "2737 2021-04-09  5100.0422  5035.3374  12841650900  2.215198e+11  0.462744   \n",
       "2738 2021-04-12  5026.9791  4947.7459  15264431400  2.672182e+11  0.550005   \n",
       "2739 2021-04-13  4949.8074  4939.6438  13291935800  2.257532e+11  0.478854   \n",
       "2740 2021-04-14  4945.6857  4980.6279  12086083800  2.210363e+11  0.435412   \n",
       "2741 2021-04-15  4969.9099  4948.9741  10882938400  2.138209e+11  0.392067   \n",
       "2742 2021-04-16  4966.8999  4966.1811  11123992400  2.133892e+11  0.400745   \n",
       "2743 2021-04-19  4966.4090  5087.0165  15476982400  3.078998e+11  0.557560   \n",
       "2744 2021-04-20  5065.7757  5083.3654  13654170000  2.766406e+11  0.491852   \n",
       "\n",
       "        pctChg  close_nomalized  volume_nomalized    avg_price  future_price  \\\n",
       "2735 -0.711995         0.810797          0.186389  5109.918017   4994.089617   \n",
       "2736  0.165874         0.813073          0.180381  5112.831267   4969.751700   \n",
       "2737 -1.503679         0.792412          0.160285  5110.660717   4978.364883   \n",
       "2738 -1.739536         0.768871          0.196743  5083.488900   5000.968133   \n",
       "2739 -0.163753         0.766694          0.167061  5046.503383           NaN   \n",
       "2740  0.829697         0.777709          0.148915  5019.884400           NaN   \n",
       "2741 -0.635538         0.769201          0.130810  4994.089617           NaN   \n",
       "2742  0.347688         0.773826          0.134437  4969.751700           NaN   \n",
       "2743  2.433165         0.806302          0.199941  4978.364883           NaN   \n",
       "2744 -0.071773         0.805321          0.172512  5000.968133           NaN   \n",
       "\n",
       "      label  label_valid  \n",
       "2735    1.0          NaN  \n",
       "2736    1.0          NaN  \n",
       "2737    1.0          NaN  \n",
       "2738    1.0          NaN  \n",
       "2739    NaN          1.0  \n",
       "2740    NaN          1.0  \n",
       "2741    NaN          1.0  \n",
       "2742    NaN          1.0  \n",
       "2743    NaN          1.0  \n",
       "2744    NaN          1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>amount</th>\n      <th>turn</th>\n      <th>pctChg</th>\n      <th>close_nomalized</th>\n      <th>volume_nomalized</th>\n      <th>avg_price</th>\n      <th>future_price</th>\n      <th>label</th>\n      <th>label_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2735</th>\n      <td>2021-04-07</td>\n      <td>5141.6556</td>\n      <td>5103.7428</td>\n      <td>14576374800</td>\n      <td>2.462712e+11</td>\n      <td>0.525246</td>\n      <td>-0.711995</td>\n      <td>0.810797</td>\n      <td>0.186389</td>\n      <td>5109.918017</td>\n      <td>4994.089617</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2736</th>\n      <td>2021-04-08</td>\n      <td>5078.2627</td>\n      <td>5112.2086</td>\n      <td>14177104700</td>\n      <td>2.284220e+11</td>\n      <td>0.510867</td>\n      <td>0.165874</td>\n      <td>0.813073</td>\n      <td>0.180381</td>\n      <td>5112.831267</td>\n      <td>4969.751700</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2737</th>\n      <td>2021-04-09</td>\n      <td>5100.0422</td>\n      <td>5035.3374</td>\n      <td>12841650900</td>\n      <td>2.215198e+11</td>\n      <td>0.462744</td>\n      <td>-1.503679</td>\n      <td>0.792412</td>\n      <td>0.160285</td>\n      <td>5110.660717</td>\n      <td>4978.364883</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2738</th>\n      <td>2021-04-12</td>\n      <td>5026.9791</td>\n      <td>4947.7459</td>\n      <td>15264431400</td>\n      <td>2.672182e+11</td>\n      <td>0.550005</td>\n      <td>-1.739536</td>\n      <td>0.768871</td>\n      <td>0.196743</td>\n      <td>5083.488900</td>\n      <td>5000.968133</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2739</th>\n      <td>2021-04-13</td>\n      <td>4949.8074</td>\n      <td>4939.6438</td>\n      <td>13291935800</td>\n      <td>2.257532e+11</td>\n      <td>0.478854</td>\n      <td>-0.163753</td>\n      <td>0.766694</td>\n      <td>0.167061</td>\n      <td>5046.503383</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2740</th>\n      <td>2021-04-14</td>\n      <td>4945.6857</td>\n      <td>4980.6279</td>\n      <td>12086083800</td>\n      <td>2.210363e+11</td>\n      <td>0.435412</td>\n      <td>0.829697</td>\n      <td>0.777709</td>\n      <td>0.148915</td>\n      <td>5019.884400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2741</th>\n      <td>2021-04-15</td>\n      <td>4969.9099</td>\n      <td>4948.9741</td>\n      <td>10882938400</td>\n      <td>2.138209e+11</td>\n      <td>0.392067</td>\n      <td>-0.635538</td>\n      <td>0.769201</td>\n      <td>0.130810</td>\n      <td>4994.089617</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2742</th>\n      <td>2021-04-16</td>\n      <td>4966.8999</td>\n      <td>4966.1811</td>\n      <td>11123992400</td>\n      <td>2.133892e+11</td>\n      <td>0.400745</td>\n      <td>0.347688</td>\n      <td>0.773826</td>\n      <td>0.134437</td>\n      <td>4969.751700</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2743</th>\n      <td>2021-04-19</td>\n      <td>4966.4090</td>\n      <td>5087.0165</td>\n      <td>15476982400</td>\n      <td>3.078998e+11</td>\n      <td>0.557560</td>\n      <td>2.433165</td>\n      <td>0.806302</td>\n      <td>0.199941</td>\n      <td>4978.364883</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2744</th>\n      <td>2021-04-20</td>\n      <td>5065.7757</td>\n      <td>5083.3654</td>\n      <td>13654170000</td>\n      <td>2.766406e+11</td>\n      <td>0.491852</td>\n      <td>-0.071773</td>\n      <td>0.805321</td>\n      <td>0.172512</td>\n      <td>5000.968133</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "x, x_valid = np.split(x, [-predict_period+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2740, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2335,)"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verification = df_verification.append(pd.Series(trend), ignore_index=True)\n",
    "# 计算盈亏\n",
    "if not simulation['bought'] and trend == 1 and prob >= 70:\n",
    "    simulation['bought'] = True\n",
    "    simulation['price'] = close\n",
    "elif simulation['bought'] and trend == 2 and prob >= 70:\n",
    "    simulation['bought'] = False\n",
    "    simulation['asset'] = simulation['asset']/simulation['price']*close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info_path = \"stock_info/\" + stock_code + \".csv\"       # 文件路径\n",
    "# 读取csv文件\n",
    "stock = pd.read_csv(stock_info_path, parse_dates=['date'])\n",
    "\n",
    "# 准备数据\n",
    "stock['close_nomalized'] = (stock['close']-stock['close'].min())/(stock['close'].max()-stock['close'].min())        # 收盘价 归一化\n",
    "stock['volume_nomalized'] = (stock['volume']-stock['volume'].min())/(stock['volume'].max()-stock['volume'].min())   # 交易量 归一化\n",
    "stock['avg_price'] = stock['close'].rolling(predict_period).mean()                                                  # 最近周期内的平均股价\n",
    "stock = stock[predict_period-1:]\n",
    "stock['future_price'] = stock['close'].rolling(predict_period).mean().shift(-predict_period)                        # 未来股价均值(不包含当日收盘价)\n",
    "# stock = stock.dropna(axis=0)                                                                                      # 去除空值\n",
    "\n",
    "def flat_or_not(x):\n",
    "    if x >= threshold_flat:\n",
    "        return 2       # 涨\n",
    "    elif x <= -threshold_flat:\n",
    "        return 1       # 跌\n",
    "    elif np.isnan(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 0       # 持平\n",
    "\n",
    "stock['label'] = ((stock['future_price'] - stock['avg_price']) / stock['avg_price']).apply(flat_or_not)\n",
    "\n",
    "n = len(stock)\n",
    "\n",
    "x = np.array([stock[['close_nomalized', 'volume_nomalized']][i:i+history_period] for i in range(n-history_period+1)]).reshape(-1, 20, 20, 2) # 输入 400天 + 交易量\n",
    "x = x[:, :, :, :, np.newaxis]\n",
    "\n",
    "x_valid = x[-40:]                                         # 标签 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 20, 20, 2, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 2341 elements, new values have 2335 elements",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-2e60bc989895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhistory_period\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mpredict_period\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_predict'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# stock.to_csv('tmp.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels, fastpath)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_index\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_subtyp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_all_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise ValueError(\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 2341 elements, new values have 2335 elements"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_model.h5')\n",
    "score = tf.nn.softmax(model(x))\n",
    "a = pd.Series([np.argmax(item) for item in score])\n",
    "a.index=stock.index[history_period-1: -predict_period]\n",
    "stock['label_predict'] = a\n",
    "# stock.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model.h5')\n",
    "score = tf.nn.softmax(model(x_valid))\n",
    "a = pd.Series([np.argmax(item) for item in score])\n",
    "a.index=stock.index[-40:]\n",
    "stock['label_valid'] = a\n",
    "stock.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}